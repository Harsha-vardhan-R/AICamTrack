{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7cedbb5-8675-488a-887b-8297bda1084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # for the super classes and layers\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func # for activation functions etc..\n",
    "from torch.utils.data import Dataset, DataChunk, DataLoader # for loading data as chunks\n",
    "from torchvision import transforms # image to tensor thing\n",
    "import torch.nn.init as init\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchsummary import summary # getting the summary of the architecture\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeaaea3-937a-4868-b61f-aa766d005e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to track two things for camera tracking, \n",
    "#    1 -> direction.\n",
    "#    2 -> location.\n",
    "#\n",
    "# The ML model aids us selecting what to track, and because we need to track the camera for more than just the objects that appear at the \n",
    "# beginning of the video, we need to drop objects and pickup new objects with the duration of the clip.\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e48365-e68f-4bd7-a1b6-e1ffe7a88023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6bdc2aca30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"shapes/output/Circle_0a0b51ca-2a86-11ea-8123-8363a7ec19e6.png\")\n",
    "changer = transforms.Compose([\n",
    "    transforms.Resize((50, 50))\n",
    "])\n",
    "img = changer(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "296cc759-5772-474c-b9f0-f7374dc61136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "class SmallShapeLearn(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes = 9):\n",
    "        super(SmallShapeLearn, self).__init__()\n",
    "        # for 200*200 as the input.\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=2)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = func.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        #  \\\n",
    "        x = func.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #   \\\n",
    "        x = func.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        #     \\\n",
    "        x = x.view(-1, 64 * 7 * 7) \n",
    "        x = func.relu(self.fc1(x))\n",
    "        #       \\\n",
    "        x = self.fc2(x)\n",
    "        #        \\\n",
    "        return func.log_softmax(x, dim=1)\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Initializing Conv2d layers with Xavier (Glorot) initialization\n",
    "                init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Initializing Linear layers with Xavier (Glorot) initialization\n",
    "                init.xavier_normal_(m.weight)\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42d5b73d-f351-464e-a49c-9bf262ce07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 50, 50]             160\n",
      "         MaxPool2d-2           [-1, 16, 25, 25]               0\n",
      "            Conv2d-3           [-1, 32, 27, 27]           4,640\n",
      "         MaxPool2d-4           [-1, 32, 13, 13]               0\n",
      "            Conv2d-5           [-1, 64, 15, 15]          18,496\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Linear-7                   [-1, 64]         200,768\n",
      "            Linear-8                    [-1, 9]             585\n",
      "================================================================\n",
      "Total params: 224,649\n",
      "Trainable params: 224,649\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.74\n",
      "Params size (MB): 0.86\n",
      "Estimated Total Size (MB): 1.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model = SmallShapeLearn(num_classes=9)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "summary(model, (1, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a2b7d-b008-4e6e-8c3c-1574bbf0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store costs and steps\n",
    "costs = []\n",
    "steps = []\n",
    "\n",
    "# Create a function to update the plot\n",
    "def update_plot(epoch, batch_idx, cost):\n",
    "    plt.plot(steps, costs, label='Cost')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title(f'Epoch {epoch + 1}, Batch {batch_idx + 1}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc4a01a7-5392-4216-84a0-bc86eb5928ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet loading\n",
    "shape_label_dictionary = {\"Triangle\" : 0,\n",
    "                          \"Square\" : 1,\n",
    "                          \"Pentagon\" : 2,\n",
    "                          \"Hexagon\" : 3,\n",
    "                          \"Heptagon\" : 4,\n",
    "                          \"Octagon\" : 5,\n",
    "                          \"Nonagon\" : 6,\n",
    "                          \"Circle\" : 7,\n",
    "                          \"Star\" : 8}\n",
    "\n",
    "class ShapeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.root_dir = path\n",
    "        self.image_files = [f for f in os.listdir(path) if f.endswith('.png')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, id):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[id])\n",
    "        image = Image.open(img_name).convert('L')\n",
    "        label = self.image_files[id].split('_')[0]\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((50, 50)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        image = transform(image)\n",
    "        label = shape_label_dictionary[label]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5f82b-bb3f-425a-8c5e-ca435fe01dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████| 2813/2813 [01:17<00:00, 36.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  39%|██████████████████████████████████▎                                                    | 1109/2813 [00:34<00:52, 32.51it/s]"
     ]
    }
   ],
   "source": [
    "# Setting up for training\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model = SmallShapeLearn(num_classes=9)\n",
    "model.initialize_weights()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "train_dataset = ShapeDataset('shapes/output')\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c68959-2ced-4362-a51e-c748ba0c0855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7a1a1-5e19-423c-9736-df314fc2815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PROTOTYPE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04213877-d3fe-4e36-88f2-50262bd9bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERS AND TRACKING #\n",
    "\n",
    "\n",
    "video_path = 'test/footage.mp4'\n",
    "video = cv2.VideoCapture(video_path)\n",
    "kernel = numpy.array([[2 , 1 , 2], \n",
    "                      [1 ,-12 , 1], \n",
    "                      [2 , 1 , 2]])\n",
    "\n",
    "kernel2 = numpy.array([[1, 1 , 2 , 1, 1],\n",
    "                      [1, 3 , 3 , 3, 1], \n",
    "                      [1, 3 ,-44 , 3,1], \n",
    "                      [1, 3 , 3 , 3, 1],\n",
    "                      [1, 1 , 2 , 1, 1]])\n",
    "\n",
    "\n",
    "kernel3 = numpy.array([[-1, -1 , -2, -1, -1],\n",
    "                      [-1, -3 , -3 , -3, -1], \n",
    "                      [-1, -3 , 50 , -3, -1], \n",
    "                      [-1, -3 , -3 , -3, -1],\n",
    "                      [-1, -1 , -2 , -1, -1]])\n",
    "\n",
    "\n",
    "def draw_lines(frame):\n",
    "    \n",
    "    lines = cv2.HoughLines(frame, 1, numpy.pi / 180, threshold=500)\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            a = numpy.cos(theta)\n",
    "            b = numpy.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Error: Could not open video file(mostly, file not found)\")\n",
    "else:\n",
    "    # play video with filters.\n",
    "    while (1):\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "        frame = cv2.resize(frame, (1920, 1080))\n",
    "\n",
    "        frame = cv2.GaussianBlur(frame, (3, 3), 0);\n",
    "        frame = cv2.filter2D(frame, -1, kernel2);\n",
    "        \n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # if the pressed key in 30 ms is `q`, quit.\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc1f5d-a7cf-4432-a01c-e7aa1ed71984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
